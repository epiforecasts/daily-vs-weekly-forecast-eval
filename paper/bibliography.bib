@article{bracher_evaluating_2021,
	title = {Evaluating epidemic forecasts in an interval format},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618},
	doi = {10.1371/journal.pcbi.1008618},
	abstract = {For practical reasons, many forecasts of case, hospitalization, and death counts in the context of the current Coronavirus Disease 2019 (COVID-19) pandemic are issued in the form of central predictive intervals at various levels. This is also the case for the forecasts collected in the COVID-19 Forecast Hub (https://covid19forecasthub.org/). Forecast evaluation metrics like the logarithmic score, which has been applied in several infectious disease forecasting challenges, are then not available as they require full predictive distributions. This article provides an overview of how established methods for the evaluation of quantile and interval forecasts can be applied to epidemic forecasts in this format. Specifically, we discuss the computation and interpretation of the weighted interval score, which is a proper score that approximates the continuous ranked probability score. It can be interpreted as a generalization of the absolute error to probabilistic forecasts and allows for a decomposition into a measure of sharpness and penalties for over- and underprediction.},
	language = {en},
	number = {2},
	urldate = {2023-12-08},
	journal = {PLOS Computational Biology},
	author = {Bracher, Johannes and Ray, Evan L. and Gneiting, Tilmann and Reich, Nicholas G.},
	month = feb,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Forecasting, Pandemics, Public and occupational health, Probability distribution, COVID 19, Epidemiological methods and statistics, Binomials, Instrument calibration},
	pages = {e1008618},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/W6FGI3IY/Bracher et al. - 2021 - Evaluating epidemic forecasts in an interval forma.pdf:application/pdf},
}

@article{abbott_estimating_2020,
	title = {Estimating the time-varying reproduction number of {SARS}-{CoV}-2 using national and subnational case counts},
	volume = {5},
	doi = {10.12688/wellcomeopenres.16006.2},
	abstract = {Background: Assessing temporal variations in transmission in different countries is essential for monitoring the epidemic, evaluating the effectiveness of public health interventions and estimating the impact of changes in policy.  Methods: We use case and death notification data to generate daily estimates of the time-varying reproduction number globally, regionally, nationally, and subnationally over a 12-week rolling window. Our modelling framework, based on open source tooling, accounts for uncertainty in reporting delays, so that the reproduction number is estimated based on underlying latent infections.  Results: Estimates of the reproduction number, trajectories of infections, and forecasts are displayed on a dedicated website as both maps and time series, and made available to download in tabular form.  Conclusions: Â This decision-support tool can be used to assess changes in virus transmission both globally, regionally, nationally, and subnationally. This allows public health officials and policymakers to track the progress of the outbreak in near real-time using an epidemiologically valid measure. As well as providing regular updates on our website, we also provide an open source tool-set so that our approach can be used directly by researchers and policymakers on confidential data-sets. We hope that our tool will be used to support decisions in countries worldwide throughout the ongoing COVID-19 pandemic.},
	journal = {Wellcome Open Research},
	author = {Abbott, Sam and Hellewell, Joel and Thompson, Robin N. and Sherratt, Katharine and Gibbs, Hamish P. and Bosse, Nikos I. and Munday, James D. and Meakin, Sophie and Doughty, Emma L. and Chun, June Young and Chan, Yung-Wai Desmond and Finger, Flavio and Campbell, Paul and Endo, Akira and Pearson, Carl A. B. and Gimma, Amy and Russell, Tim and Flasche, Stefan and Kucharski, Adam J. and Eggo, Rosalind M. and Funk, Sebastian},
	year = {2020},
	pages = {112},
	file = {PDF:/Users/lshja16/Zotero/storage/447543YX/783df57d-76b0-4eeb-ac4d-7719ab7ea7ee_16006_-_sam_abbott_v2.pdf:application/pdf},
}

@misc{betancourt_conceptual_2018,
	title = {A {Conceptual} {Introduction} to {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1701.02434},
	doi = {10.48550/arXiv.1701.02434},
	abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
	urldate = {2024-01-09},
	publisher = {arXiv},
	author = {Betancourt, Michael},
	month = jul,
	year = {2018},
	note = {arXiv:1701.02434 [stat]},
	keywords = {Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/lshja16/Zotero/storage/Z32CQVXU/Betancourt - 2018 - A Conceptual Introduction to Hamiltonian Monte Car.pdf:application/pdf;arXiv.org Snapshot:/Users/lshja16/Zotero/storage/WG7YPLIK/1701.html:text/html;Snapshot:/Users/lshja16/Zotero/storage/WXEASQJL/1701.html:text/html;Snapshot:/Users/lshja16/Zotero/storage/FTIZN2D6/1701.html:text/html},
}

@article{reich_collaborative_2022,
	title = {Collaborative {Hubs}: {Making} the {Most} of {Predictive} {Epidemic} {Modeling}},
	volume = {112},
	issn = {0090-0036},
	shorttitle = {Collaborative {Hubs}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9137029/},
	doi = {10.2105/AJPH.2022.306831},
	number = {6},
	urldate = {2025-04-10},
	journal = {American Journal of Public Health},
	author = {Reich, Nicholas G. and Lessler, Justin and Funk, Sebastian and Viboud, Cecile and Vespignani, Alessandro and Tibshirani, Ryan J. and Shea, Katriona and Schienle, Melanie and Runge, Michael C. and Rosenfeld, Roni and Ray, Evan L. and Niehus, Rene and Johnson, Helen C. and Johansson, Michael A. and Hochheiser, Harry and Gardner, Lauren and Bracher, Johannes and Borchering, Rebecca K. and Biggerstaff, Matthew},
	month = jun,
	year = {2022},
	pmid = {35420897},
	pmcid = {PMC9137029},
	pages = {839--842},
	file = {PubMed Central Full Text PDF:/Users/lshja16/Zotero/storage/5WHV6NW5/Reich et al. - 2022 - Collaborative Hubs Making the Most of Predictive Epidemic Modeling.pdf:application/pdf},
}

@misc{lauer_infectious_2020,
	title = {Infectious {Disease} {Forecasting} for {Public} {Health}},
	url = {http://arxiv.org/abs/2006.00073},
	doi = {10.48550/arXiv.2006.00073},
	abstract = {Forecasting transmission of infectious diseases, especially for vector-borne diseases, poses unique challenges for researchers. Behaviors of and interactions between viruses, vectors, hosts, and the environment each play a part in determining the transmission of a disease. Public health surveillance systems and other sources provide valuable data that can be used to accurately forecast disease incidence. However, many aspects of common infectious disease surveillance data are imperfect: cases may be reported with a delay or in some cases not at all, data on vectors may not be available, and case data may not be available at high geographical or temporal resolution. In the face of these challenges, researchers must make assumptions to either account for these underlying processes in a mechanistic model or to justify their exclusion altogether in a statistical model. Whether a model is mechanistic or statistical, researchers should evaluate their model using accepted best practices from the emerging field of infectious disease forecasting while adopting conventions from other fields that have been developing forecasting methods for decades. Accounting for assumptions and properly evaluating models will allow researchers to generate forecasts that have the potential to provide valuable insights for public health officials. This chapter provides a background to the practice of forecasting in general, discusses the biological and statistical models used for infectious disease forecasting, presents technical details about making and evaluating forecasting models, and explores the issues in communicating forecasting results in a public health context.},
	urldate = {2025-04-10},
	publisher = {arXiv},
	author = {Lauer, Stephen A. and Brown, Alexandria C. and Reich, Nicholas G.},
	month = may,
	year = {2020},
	note = {arXiv:2006.00073 [stat]},
	keywords = {Statistics - Applications},
	file = {Preprint PDF:/Users/lshja16/Zotero/storage/DN3L4G8B/Lauer et al. - 2020 - Infectious Disease Forecasting for Public Health.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/TGCLZ463/2006.html:text/html},
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distributionF if he or she issues the probabilistic forecast F, rather than G â‰  F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
	number = {477},
	urldate = {2025-04-10},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and and Raftery, Adrian E},
	month = mar,
	year = {2007},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1198/016214506000001437},
	keywords = {Bayes factor, Bregman divergence, Brier score, Coherent, Continuous ranked probability score, Cross-validation, Entropy, Kernel score, Loss function, Minimum contrast estimation, Negative definite function, Prediction interval, Predictive distribution, Quantile forecast, Scoring rule, Skill score, Strictly proper, Utility function},
	pages = {359--378},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/3D4X3TDC/Gneiting and and Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Estimation.pdf:application/pdf},
}

@misc{abbott_epinow2_2025,
	title = {{EpiNow2}: {Estimate} {Real}-{Time} {Case} {Counts} and {Time}-{Varying} {Epidemiological} {Parameters}},
	shorttitle = {{EpiNow2}},
	url = {https://zenodo.org/records/14899316},
	abstract = {Estimates the time-varying reproduction number, rate of spread, and doubling time using a range of open-source tools (Abbott et al. (2020) ), and current best practices (Gostic et al. (2020) ). It aims to help users avoid some of the limitations of naive implementations in a framework that is informed by community feedback and is actively supported.},
	urldate = {2025-04-10},
	publisher = {Zenodo},
	author = {Abbott, Sam and Hellewell, Joel and Sherratt, Katharine and Gostic, Katelyn and Hickson, Joe and Badr, Hamada S. and DeWitt, Michael and Azam, James M. and EpiForecasts and Funk, Sebastian},
	month = feb,
	year = {2025},
	doi = {10.5281/zenodo.14899316},
	keywords = {covid-19, backcalculation, gaussian-processes, open-source, reproduction-number, rstats, stan},
	file = {Snapshot:/Users/lshja16/Zotero/storage/KWSF4W7I/14899316.html:text/html},
}

@misc{marivate_coronavirus_2020,
	title = {Coronavirus disease ({COVID}-19) case data - {South} {Africa}},
	url = {https://zenodo.org/records/3819126},
	doi = {10.5281/zenodo.3819126},
	abstract = {COVID 19 Data for South Africa created, maintained and hosted byÂ DSFSI research groupÂ at the University of Pretoria


Disclaimer:Â We have worked to keep the data as accurate as possible. We collate the COVID 19 reporting data from NICD and South Africa DoH. We only update that data once there is an official report or statement. For the other data, we work to keep the data as accurate as possible. If you find errors let us know.Â 


See original GitHub repo for detailed informationÂ https://github.com/dsfsi/covid19za},
	urldate = {2025-04-10},
	publisher = {Zenodo},
	author = {Marivate, Vukosi and Arbi, Riaz and Combrink, Herkulaas and de Waal, Alta and Dryza, Henkho and Egersdorfer, Derrick and Garnett, Shaun and Gordon, Brent and Greyling, Lizel and Lebogo, Ofentswe and Mackie, Dave and Merry, Bruce and Mkhondwane, S'busiso and Mokoatle, Mpho and Moodley, Shivan and Mtsweni, Jabu and Mtsweni, Nompumelelo and Myburgh, Paul and Richter, Jannik and Rikhotso, Vuthlari and Rosen, Simon and Sefara, Joseph and van der Walt, Anelda and van Heerden, Schalk and Welsh, Jay},
	month = mar,
	year = {2020},
	keywords = {coronavirus, covid19, dataset},
	file = {Snapshot:/Users/lshja16/Zotero/storage/EP3LS29M/3819126.html:text/html},
}

@article{marivate_use_2020,
	title = {Use of {Available} {Data} {To} {Inform} {The} {COVID}-19 {Outbreak} in {South} {Africa}: {A} {Case} {Study}},
	volume = {19},
	issn = {1683-1470},
	shorttitle = {Use of {Available} {Data} {To} {Inform} {The} {COVID}-19 {Outbreak} in {South} {Africa}},
	url = {https://datascience.codata.org/articles/10.5334/dsj-2020-019},
	doi = {10.5334/dsj-2020-019},
	abstract = {The coronavirus disease (COVID-19), caused by the SARS-CoV-2 virus, was declared a pandemic by the World Health Organization (WHO) in February 2020. Currently, there are no vaccines or treatments that have been approved after clinical trials. Social distancing measures, including travel bans, school closure, and quarantine applied to countries or regions are being used to limit the spread of the disease, and the demand on the healthcare infrastructure. The seclusion of groups and individuals has led to limited access to accurate information. To update the public, especially in South Africa, announcements are made by the minister of health daily. These announcements narrate the confirmed COVID-19 cases and include the age, gender, and travel history of people who have tested positive for the disease. Additionally, the South African National Institute for Communicable Diseases updates a daily infographic summarising the number of tests performed, confirmed cases, mortality rate, and the regions affected. However, the age of the patient and other nuanced data regarding the transmission is only shared in the daily announcements and not on the updated infographic. To disseminate this information, the Data Science for Social Impact research group at the University of Pretoria, South Africa, has worked on curating and applying publicly available data in a way that is computer readable so that information can be shared to the public â€“ using both a data repository and a dashboard. Through collaborative practices, a variety of challenges related to publicly available data in South Africa came to the fore. These include shortcomings in the accessibility, integrity, and data management practices between governmental departments and the South African public. In this paper, solutions to these problems will be shared by using a publicly available data repository and dashboard as a case study.Â Dashboard: https://dsfsi.github.io/covid19za-dash/, Data repository: https://github.com/dsfsi/covid19za.},
	language = {en-US},
	number = {1},
	urldate = {2025-04-10},
	journal = {Data Science Journal},
	author = {Marivate, Vukosi and Combrink, Herkulaas MvE},
	month = may,
	year = {2020},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/BAUYPQMT/Marivate and Combrink - 2020 - Use of Available Data To Inform The COVID-19 Outbreak in South Africa A Case Study.pdf:application/pdf},
}

@article{vehtari_rank-normalization_2021,
	title = {Rank-normalization, folding, and localization: {An} improved \${\textbackslash}widehat\{{R}\}\$ for assessing convergence of {MCMC}},
	volume = {16},
	issn = {1936-0975},
	shorttitle = {Rank-normalization, folding, and localization},
	url = {http://arxiv.org/abs/1903.08008},
	doi = {10.1214/20-BA1221},
	abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic \${\textbackslash}widehat\{R\}\$ of Gelman and Rubin (1992) has serious flaws. Traditional \${\textbackslash}widehat\{R\}\$ will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
	number = {2},
	urldate = {2025-04-10},
	journal = {Bayesian Analysis},
	author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and BÃ¼rkner, Paul-Christian},
	month = jun,
	year = {2021},
	note = {arXiv:1903.08008 [stat]},
	keywords = {Statistics - Methodology, Statistics - Computation},
	file = {Preprint PDF:/Users/lshja16/Zotero/storage/8HKZEY6M/Vehtari et al. - 2021 - Rank-normalization, folding, and localization An improved \$widehat R \$ for assessing convergence o.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/2HMIK3Y2/1903.html:text/html},
}

@article{doms_assessing_2018,
	title = {Assessing the {Use} of {Influenza} {Forecasts} and {Epidemiological} {Modeling} in {Public} {Health} {Decision} {Making} in the {United} {States}},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-30378-w},
	doi = {10.1038/s41598-018-30378-w},
	abstract = {Although forecasts and other mathematical models have the potential to play an important role in mitigating the impact of infectious disease outbreaks, the extent to which these tools are used in public health decision making in the United States is unclear. Throughout 2015, we invited public health practitioners belonging to three national public health organizations to complete a cross-sectional survey containing questions on model awareness, model use, and communication with modelers. Of 39 respondents, 46.15\% used models in their work, and 20.51\% reported direct communication with those who create models. Over half (64.10\%) were aware that influenza forecasts exist. The need for improved communication between practitioners and modelers was overwhelmingly endorsed, with over 50\% of participants indicating the need for models more relevant to public health questions, increased frequency of telecommunication, and more plain language in discussing models. Model use for public health decision making must be improved if models are to reach their full potential as public health tools. Increased quality and frequency of communication between practitioners and modelers could be particularly useful in achieving this goal. It is important that improvements be made now, rather than waiting for the next public health crisis to occur.},
	language = {en},
	number = {1},
	urldate = {2025-04-11},
	journal = {Scientific Reports},
	author = {Doms, Colin and Kramer, Sarah C. and Shaman, Jeffrey},
	month = aug,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Epidemiology, Computational models, Influenza virus},
	pages = {12406},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/6BKVZD7H/Doms et al. - 2018 - Assessing the Use of Influenza Forecasts and Epidemiological Modeling in Public Health Decision Maki.pdf:application/pdf},
}

@article{meltzer_modeling_2016,
	title = {Modeling in {Real} {Time} {During} the {Ebola} {Response}},
	volume = {65},
	issn = {2380-89502380-8942},
	url = {https://www.cdc.gov/mmwr/volumes/65/su/su6503a12.htm},
	doi = {10.15585/mmwr.su6503a12},
	abstract = {CDC analyzes modeling projects initiated to aid decision-making during the Ebola epidemic.},
	language = {en-us},
	urldate = {2025-04-11},
	journal = {MMWR Supplements},
	author = {Meltzer, Martin I.},
	year = {2016},
	file = {Full Text:/Users/lshja16/Zotero/storage/N27CJKZG/Meltzer - 2016 - Modeling in Real Time During the Ebola Response.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/PYHG4BQA/su6503a12.html:text/html},
}

@article{carias_forecasting_2019,
	title = {Forecasting the 2014 {West} {African} {Ebola} {Outbreak}},
	volume = {41},
	issn = {1478-6729},
	url = {https://doi.org/10.1093/epirev/mxz013},
	doi = {10.1093/epirev/mxz013},
	abstract = {In 2014â€“2015, a large Ebola outbreak afflicted Liberia, Guinea, and Sierra Leone. We performed a systematic review of 26 manuscripts, published between 2014 and April 2015, that forecasted the West African Ebola outbreak while it was occurring, and we derived implications for how results could be interpreted by policymakers. Forecasted case counts varied widely. An important determinant of forecast accuracy for case counts was how far into the future predictions were made. Generally, forecasts for less than 2 months into the future tended to be more accurate than those made for more than 10 weeks into the future. The exceptions were parsimonious statistical models in which the decay of the rate of spread of the pathogen among susceptible individuals was dealt with explicitly. The most important lessons for policymakers regarding future outbreaks, when using similar modeling results, are: 1) uncertainty of forecasts will be greater in the beginning of the outbreak; 2) when data are limited, forecasts produced by models designed to inform specific decisions should be used complementarily for robust decision-making (e.g., 2 statistical models produced the most reliable case-counts forecasts for the studied Ebola outbreak but did not enable understanding of interventionsâ€™ impact, whereas several compartmental models could estimate interventionsâ€™ impact but required unavailable data); and 3) timely collection of essential data is necessary for optimal model use.},
	number = {1},
	urldate = {2025-04-11},
	journal = {Epidemiologic Reviews},
	author = {Carias, Cristina and Oâ€™Hagan, Justin J and Gambhir, Manoj and Kahn, Emily B and Swerdlow, David L and Meltzer, Martin I},
	month = jan,
	year = {2019},
	pages = {34--50},
	file = {Snapshot:/Users/lshja16/Zotero/storage/FJWEWMEX/5634001.html:text/html},
}

@article{tabataba_framework_2017,
	title = {A framework for evaluating epidemic forecasts},
	volume = {17},
	issn = {1471-2334},
	url = {https://doi.org/10.1186/s12879-017-2365-1},
	doi = {10.1186/s12879-017-2365-1},
	abstract = {Over the past few decades, numerous forecasting methods have been proposed in the field of epidemic forecasting. Such methods can be classified into different categories such as deterministic vs. probabilistic, comparative methods vs. generative methods, and so on. In some of the more popular comparative methods, researchers compare observed epidemiological data from the early stages of an outbreak with the output of proposed models to forecast the future trend and prevalence of the pandemic. A significant problem in this area is the lack of standard well-defined evaluation measures to select the best algorithm among different ones, as well as for selecting the best possible configuration for a particular algorithm.},
	number = {1},
	urldate = {2025-04-11},
	journal = {BMC Infectious Diseases},
	author = {Tabataba, Farzaneh Sadat and Chakraborty, Prithwish and Ramakrishnan, Naren and Venkatramanan, Srinivasan and Chen, Jiangzhuo and Lewis, Bryan and Marathe, Madhav},
	month = may,
	year = {2017},
	keywords = {Epidemic forecasting, Epidemic-Features, Error Measure, Performance evaluation, Ranking},
	pages = {345},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/AVT6GK57/Tabataba et al. - 2017 - A framework for evaluating epidemic forecasts.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/FA5FMHLM/s12879-017-2365-1.html:text/html;Snapshot:/Users/lshja16/Zotero/storage/S72NC94R/s12879-017-2365-1.html:text/html},
}

@article{funk_assessing_2019,
	title = {Assessing the performance of real-time epidemic forecasts: {A} case study of {Ebola} in the {Western} {Area} region of {Sierra} {Leone}, 2014-15},
	volume = {15},
	issn = {1553-7358},
	shorttitle = {Assessing the performance of real-time epidemic forecasts},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006785},
	doi = {10.1371/journal.pcbi.1006785},
	abstract = {Real-time forecasts based on mathematical models can inform critical decision-making during infectious disease outbreaks. Yet, epidemic forecasts are rarely evaluated during or after the event, and there is little guidance on the best metrics for assessment. Here, we propose an evaluation approach that disentangles different components of forecasting ability using metrics that separately assess the calibration, sharpness and bias of forecasts. This makes it possible to assess not just how close a forecast was to reality but also how well uncertainty has been quantified. We used this approach to analyse the performance of weekly forecasts we generated in real time for Western Area, Sierra Leone, during the 2013â€“16 Ebola epidemic in West Africa. We investigated a range of forecast model variants based on the model fits generated at the time with a semi-mechanistic model, and found that good probabilistic calibration was achievable at short time horizons of one or two weeks ahead but model predictions were increasingly unreliable at longer forecasting horizons. This suggests that forecasts may have been of good enough quality to inform decision making based on predictions a few weeks ahead of time but not longer, reflecting the high level of uncertainty in the processes driving the trajectory of the epidemic. Comparing forecasts based on the semi-mechanistic model to simpler null models showed that the best semi-mechanistic model variant performed better than the null models with respect to probabilistic calibration, and that this would have been identified from the earliest stages of the outbreak. As forecasts become a routine part of the toolkit in public health, standards for evaluation of performance will be important for assessing quality and improving credibility of mathematical models, and for elucidating difficulties and trade-offs when aiming to make the most useful and reliable forecasts.},
	language = {en},
	number = {2},
	urldate = {2025-05-19},
	journal = {PLOS Computational Biology},
	author = {Funk, Sebastian and Camacho, Anton and Kucharski, Adam J. and Lowe, Rachel and Eggo, Rosalind M. and Edmunds, W. John},
	month = feb,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Epidemiology, Infectious diseases, Mathematical models, Forecasting, Sierra Leone, Infectious disease epidemiology, Public and occupational health, Probability distribution},
	pages = {e1006785},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/NBJDSIRI/Funk et al. - 2019 - Assessing the performance of real-time epidemic forecasts A case study of Ebola in the Western Area.pdf:application/pdf},
}

@misc{conway_joint_2024,
	title = {Joint estimation of the effective reproduction number and daily incidence in the presence of aggregated and missing data},
	copyright = {Â© 2024, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.medrxiv.org/content/10.1101/2024.06.06.24308584v1},
	doi = {10.1101/2024.06.06.24308584},
	abstract = {Disease surveillance is an integral component of government policy, allowing public health professionals to monitor transmission of infectious diseases and appropriately apply interventions. To aid with surveillance efforts, there has been extensive development of mathematical models to help inform policy decisions, However, these mathematical models rely upon data streams that are expensive and often only practical for high income countries. With a growing focus on equitable public health tools there is a dire need for development of mathematical models that are equipped to handle the data stream challenges prevalent in low and middle income countries, where data is often incomplete and subject to aggregation. To address this need, we develop a mathematical model for the joint estimation of the effective reproduction number and daily incidence of an infectious disease using incomplete and aggregated data. Our investigation demonstrates that this novel mathematical model is robust across a variety of reduced data streams, making it suitable for application in diverse regions.
Author summary Monitoring the transmission of infectious diseases is an important part of government policy that is often hindered by limitations in data streams. This is especially true in low and middle income countries where health sectors have less funding. In this work we develop a mathematical model to enhance disease surveillance by overcoming these data limitations, providing accurate inferences of relevant epidemiological parameters.},
	language = {en},
	urldate = {2025-06-11},
	publisher = {medRxiv},
	author = {Conway, Eamon and Mueller, Ivo},
	month = jun,
	year = {2024},
	note = {Pages: 2024.06.06.24308584},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/4QKVXIVY/Conway and Mueller - 2024 - Joint estimation of the effective reproduction number and daily incidence in the presence of aggrega.pdf:application/pdf},
}

@article{nash_estimating_2023,
	title = {Estimating the epidemic reproduction number from temporally aggregated incidence data: {A} statistical modelling approach and software tool},
	volume = {19},
	issn = {1553-7358},
	shorttitle = {Estimating the epidemic reproduction number from temporally aggregated incidence data},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011439},
	doi = {10.1371/journal.pcbi.1011439},
	abstract = {The time-varying reproduction number (Rt) is an important measure of epidemic transmissibility that directly informs policy decisions and the optimisation of control measures. EpiEstim is a widely used opensource software tool that uses case incidence and the serial interval (SI, time between symptoms in a case and their infector) to estimate Rt in real-time. The incidence and the SI distribution must be provided at the same temporal resolution, which can limit the applicability of EpiEstim and other similar methods, e.g. for contexts where the time window of incidence reporting is longer than the mean SI. In the EpiEstim R package, we implement an expectation-maximisation algorithm to reconstruct daily incidence from temporally aggregated data, from which Rt can then be estimated. We assess the validity of our method using an extensive simulation study and apply it to COVID-19 and influenza data. For all datasets, the influence of intra-weekly variability in reported data was mitigated by using aggregated weekly data. Rt estimated on weekly sliding windows using incidence reconstructed from weekly data was strongly correlated with estimates from the original daily data. The simulation study revealed that Rt was well estimated in all scenarios and regardless of the temporal aggregation of the data. In the presence of weekend effects, Rt estimates from reconstructed data were more successful at recovering the true value of Rt than those obtained from reported daily data. These results show that this novel method allows Rt to be successfully recovered from aggregated data using a simple approach with very few data requirements. Additionally, by removing administrative noise when daily incidence data are reconstructed, the accuracy of Rt estimates can be improved.},
	language = {en},
	number = {8},
	urldate = {2025-07-24},
	journal = {PLOS Computational Biology},
	author = {Nash, Rebecca K. and Bhatt, Samir and Cori, Anne and Nouvellet, Pierre},
	month = aug,
	year = {2023},
	note = {Publisher: Public Library of Science},
	keywords = {Epidemiology, Influenza, Algorithms, COVID 19, Virus testing, Simulation and modeling, Pathogens, Solid-phase extraction},
	pages = {e1011439},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/4ZJF7QTS/Nash et al. - 2023 - Estimating the epidemic reproduction number from temporally aggregated incidence data A statistical.pdf:application/pdf},
}

@article{ogi-gittins_simulation-based_2025,
	title = {Simulation-based inference of the time-dependent reproduction number from temporally aggregated and under-reported disease incidence time series data},
	volume = {383},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2024.0412},
	doi = {10.1098/rsta.2024.0412},
	abstract = {During infectious disease outbreaks, the time-dependent reproduction number (ð‘…ð‘¡) can be estimated to monitor pathogen transmission. In previous work, we developed a simulation-based method for estimating ð‘…ð‘¡ from temporally aggregated disease incidence data (e.g. weekly case reports). While that approach is straightforward to use, it assumes implicitly that all cases are reported and the computation can be slow when applied to large datasets. In this article, we extend our previous approach and develop a computationally efficient simulation-based method for estimating ð‘…ð‘¡ in real-time accounting for both temporal aggregation of incidence data and under-reporting (with a fixed reporting probability per case). Using simulated data, we show that failing to consider stochastic under-reporting can lead to inappropriately precise estimates, including scenarios in which the true ð‘…ð‘¡ value lies outside inferred credible intervals more often than expected. We then apply our approach to data from the 2018 to 2020 Ebola outbreak in the Democratic Republic of the Congo (DRC), again exploring the effects of case under-reporting. Finally, we show how our method can be extended to account for temporal variations in reporting. Given information about the level of case reporting, our framework can be used to estimate ð‘…ð‘¡ during future outbreaks with under-reported and temporally aggregated case data.
This article is part of the theme issue â€˜Uncertainty quantification for healthcare and biological systems (Part 2)â€™.},
	number = {2293},
	urldate = {2025-07-25},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Ogi-Gittins, Isaac and Steyn, Nicholas and Polonsky, Jonathan and Hart, William S. and Keita, Mory and Ahuka-Mundeke, Steve and Hill, Edward M. and Thompson, Robin N.},
	month = apr,
	year = {2025},
	note = {Publisher: Royal Society},
	keywords = {Ebola virus disease, approximate Bayesian computation, infectious disease outbreak, public health measures, stochastic simulations, time-dependent reproduction number},
	pages = {20240412},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/V72GGJZG/Ogi-Gittins et al. - 2025 - Simulation-based inference of the time-dependent reproduction number from temporally aggregated and.pdf:application/pdf},
}

@article{steyn_primer_2025,
	title = {A {Primer} on {Inference} and {Prediction} {With} {Epidemic} {Renewal} {Models} and {Sequential} {Monte} {Carlo}},
	volume = {44},
	copyright = {Â© 2025 The Author(s). Statistics in Medicine published by John Wiley \& Sons Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.70204},
	doi = {10.1002/sim.70204},
	abstract = {Renewal models are widely used in statistical epidemiology as semi-mechanistic models of disease transmission. While primarily used for estimating the instantaneous reproduction number, they can also be used for generating projections, estimating elimination probabilities, modeling the effect of interventions, and more. We demonstrate how simple sequential Monte Carlo methods (also known as particle filters) can be used to perform inference on these models. Our goal is to acquaint a reader who has a working knowledge of statistical inference with these methods and models and to provide a practical guide to their implementation. We focus on these methods' flexibility and their ability to handle multiple statistical and other biases simultaneously. We leverage this flexibility to unify existing methods for estimating the instantaneous reproduction number and generating projections. A companion website SMC and epidemic renewal models provides additional worked examples, self-contained code to reproduce the examples presented here, and additional materials.},
	language = {en},
	number = {18-19},
	urldate = {2025-08-22},
	journal = {Statistics in Medicine},
	author = {Steyn, Nicholas and Parag, Kris V. and Thompson, Robin N. and Donnelly, Christl A.},
	year = {2025},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.70204},
	pages = {e70204},
	file = {Full Text PDF:/Users/lshja16/Zotero/storage/V438A9AS/Steyn et al. - 2025 - A Primer on Inference and Prediction With Epidemic Renewal Models and Sequential Monte Carlo.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/HQ3BQ7G2/sim.html:text/html},
}

@book{mcelreath_statistical_2018,
	title = {Statistical rethinking: {A} {Bayesian} course with examples in {R} and {Stan}},
	publisher = {Chapman and Hall/CRC},
	author = {McElreath, Richard},
	year = {2018},
}

@incollection{stan_development_team_stan_2025,
	title = {Stan {Modeling} {Language} {Reference} {Manual}, version 2.36},
	url = {https://mc-stan.org/docs/2_36/reference-manual/index.html},
	booktitle = {Stan {Modeling} {Language} {Reference} {Manual}, version 2.36},
	author = {{Stan Development Team}},
	year = {2025},
}

@misc{betancourt_identity_2020,
	title = {Identity {Crisis}},
	url = {https://betanalpha.github.io/assets/case_studies/identifiability.html},
	urldate = {2025-08-26},
	author = {Betancourt, Michael},
	month = jun,
	year = {2020},
	file = {Identity Crisis:/Users/lshja16/Zotero/storage/Y8N3LJKD/identifiability.html:text/html},
}

@misc{r_core_team_r_2025,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2025},
}

@misc{noauthor_gnu_2006,
	title = {{GNU} {Make}},
	url = {https://www.gnu.org/software/make/},
	publisher = {Free Software Foundation},
	year = {2006},
}

@misc{lambert_epiparameter_2025,
	title = {epiparameter: {Classes} and {Helper} {Functions} for {Working} with {Epidemiological} {Parameters}},
	url = {https://epiverse-trace.github.io/epiparameter/},
	author = {Lambert, Joshua W. and Kucharski, Adam and Tamayo Cuartero, Carmen},
	year = {2025},
}

@misc{bosse_evaluating_2024,
	title = {Evaluating {Forecasts} with scoringutils in {R}},
	url = {http://arxiv.org/abs/2205.07090},
	doi = {10.48550/arXiv.2205.07090},
	abstract = {Evaluating forecasts is essential to understand and improve forecasting and make forecasts useful to decision makers. A variety of R packages provide a broad variety of scoring rules, visualisations and diagnostic tools. One particular challenge, which scoringutils aims to address, is handling the complexity of evaluating and comparing forecasts from several forecasters across multiple dimensions such as time, space, and different types of targets. scoringutils extends the existing landscape by offering a convenient and flexible data.table-based framework for evaluating and comparing probabilistic forecasts (forecasts represented by a full predictive distribution). Notably, scoringutils is the first package to offer extensive support for probabilistic forecasts in the form of predictive quantiles, a format that is currently used by several infectious disease Forecast Hubs. The package is easily extendable, meaning that users can supply their own scoring rules or extend existing classes to handle new types of forecasts. scoringutils provides broad functionality to check the data and diagnose issues, to visualise forecasts and missing data, to transform data before scoring, to handle missing forecasts, to aggregate scores, and to visualise the results of the evaluation. The paper presents the package and its core functionality and illustrates common workflows using example data of forecasts for COVID-19 cases and deaths submitted to the European COVID-19 Forecast Hub.},
	urldate = {2025-08-29},
	publisher = {arXiv},
	author = {Bosse, Nikos I. and Gruson, Hugo and Cori, Anne and Leeuwen, Edwin van and Funk, Sebastian and Abbott, Sam},
	month = nov,
	year = {2024},
	note = {arXiv:2205.07090 [stat]},
	keywords = {Statistics - Applications, Statistics - Methodology, Statistics - Computation},
	file = {Preprint PDF:/Users/lshja16/Zotero/storage/HEFR4QNV/Bosse et al. - 2024 - Evaluating Forecasts with scoringutils in R.pdf:application/pdf;Snapshot:/Users/lshja16/Zotero/storage/NJ9CNST7/2205.html:text/html},
}

@article{jordan_evaluating_2019,
	title = {Evaluating {Probabilistic} {Forecasts} with {scoringRules}},
	volume = {90},
	copyright = {Copyright (c) 2019 Alexander Jordan, Fabian KrÃ¼ger, Sebastian Lerch},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v090.i12},
	doi = {10.18637/jss.v090.i12},
	abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The scoringRules package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
	language = {en},
	urldate = {2025-08-29},
	journal = {Journal of Statistical Software},
	author = {Jordan, Alexander and KrÃ¼ger, Fabian and Lerch, Sebastian},
	month = aug,
	year = {2019},
	keywords = {R, proper scoring rules, comparative evaluation, ensemble forecasts, out-of-sample evaluation, predictive distributions, score computation},
	pages = {1--37},
	file = {Full Text:/Users/lshja16/Zotero/storage/WPC4YVP6/Jordan et al. - 2019 - Evaluating Probabilistic Forecasts with scoringRules.pdf:application/pdf},
}

@misc{banholzer_comparison_2023,
	title = {A comparison of short-term probabilistic forecasts for the incidence of {COVID}-19 using mechanistic and statistical time series models},
	url = {http://arxiv.org/abs/2305.00933},
	doi = {10.48550/arXiv.2305.00933},
	abstract = {Mechanistic models enable the explicit representation of disease transmission processes, whereas statistical time series models represent these processes more implicitly. In light of the trade-offs between the two modeling approaches, we performed an empirical comparison of probabilistic forecasts from both modeling approaches for the daily incidence of COVID-19. The comparison is based on data across six large U.S. states over the first pandemic year. We evaluated probabilistic forecasts from ensembles of mechanistic models based on renewal equations and statistical time series models including autoregressive moving average (ARMA), generalized autoregressive score (GAS), and exponential smoothing (ETS) models. We find that forecasts from statistical time series models are overall at least as accurate as forecasts from mechanistic models. This result is driven by the relatively better performance of statistical models for longer forecast horizons (more than 7 days ahead). Moreover, statistical time series models better capture the volatility in the trajectory of COVID-19 incidence than mechanistic models. In scenarios with increased data uncertainty and increased variability, as they appeared during the COVID-19 pandemic, statistical time series models thus may serve as useful benchmark models.},
	urldate = {2025-04-25},
	publisher = {arXiv},
	author = {Banholzer, Nicolas and Mellan, Thomas and Unwin, H. Juliette T. and Feuerriegel, Stefan and Mishra, Swapnil and Bhatt, Samir},
	month = may,
	year = {2023},
	note = {arXiv:2305.00933 [stat]},
	keywords = {Statistics - Applications},
}

@article{nash_realtime_2022,
	title = {Real-time estimation of the epidemic reproduction number: {Scoping} review of the applications and challenges},
	volume = {1},
	issn = {2767-3170},
	shorttitle = {Real-time estimation of the epidemic reproduction number},
	url = {https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000052},
	doi = {10.1371/journal.pdig.0000052},
	abstract = {The time-varying reproduction number (Rt) is an important measure of transmissibility during outbreaks. Estimating whether and how rapidly an outbreak is growing (Rt > 1) or declining (Rt < 1) can inform the design, monitoring and adjustment of control measures in real-time. Estimating Rt comes with methodological and practical challenges, such as the choice of method, data requirements and data quality issues, which may not be immediately obvious. We carried out a scoping review to identify applications of real-time Rt estimation methods. Using EpiEstim as a case study, we evaluated the contexts in which Rt estimation methods have been used and identify unmet needs. We found that EpiEstim has been applied to a wide range of outbreaks, predominantly based on confirmed case data. We identified important issues around data used as inputs for EpiEstim, including challenges in data availability and data quality, as well as the interpretation of Rt estimates in the presence of varying reporting delays and changes in surveillance systems. Our analysis highlights the need for guidance regarding the use of Rt estimation methods in different contexts, additional tools to enhance their interpretation, and better communication of their limitations.},
	language = {en},
	number = {6},
	urldate = {2025-04-10},
	journal = {PLOS Digital Health},
	author = {Nash, Rebecca K. and Nouvellet, Pierre and Cori, Anne},
	month = jun,
	year = {2022},
	note = {Publisher: Public Library of Science},
	pages = {e0000052},
}

@article{mitchell_proper_2017,
	title = {Proper scoring rules for interval probabilistic forecasts},
	volume = {143},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3029},
	doi = {10.1002/qj.3029},
	abstract = {Interval probabilistic forecasts for binary events such as 'chance of rain: 10â€“20\%' are a convenient and natural way of expressing uncertainty in a forecast, while allowing the forecaster some ambiguity. We derive a general characterization of scoring rules that are proper for interval probabilistic forecasts, and determine particular scoring rules that correspond to familiar scoring rules used for probabilistic forecasts given as precise probabilities.},
	language = {en},
	number = {704},
	urldate = {2025-04-25},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Mitchell, K. and Ferro, C. A. T.},
	year = {2017},
	note = {\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3029},
	pages = {1597--1607},
}

@misc{pic_proper_2024,
	title = {Proper {Scoring} {Rules} for {Multivariate} {Probabilistic} {Forecasts} based on {Aggregation} and {Transformation}},
	url = {http://arxiv.org/abs/2407.00650},
	doi = {10.48550/arXiv.2407.00650},
	abstract = {Proper scoring rules are an essential tool to assess the predictive performance of probabilistic forecasts. However, propriety alone does not ensure an informative characterization of predictive performance. For instance, proper scoring rules may lack useful interpretations, such as those related to calibration and sharpness, or they may fail to account for forecast attributes that are important in practice. We formalize a framework based on aggregation and transformation to build interpretable multivariate proper scoring rules. Aggregation-and-transformation-based (AT-based) scoring rules are able to target specific features of the probabilistic forecasts, including marginal calibration, dependency calibration, sharpness, conditional calibration, and the performance for specific outcomes. Existing multivariate proper scoring rules can be represented under this framework, and we further build on it to construct new scoring rules based on strictly proper scoring rules that incorporate desired conditional and unconditional forecast properties.},
	urldate = {2025-04-25},
	publisher = {arXiv},
	author = {Pic, Romain and Dombry, ClÃ©ment and Naveau, Philippe and Taillardat, Maxime},
	month = jul,
	year = {2024},
	note = {arXiv:2407.00650 [math, stat]},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
}

@article{murphy_what_1993,
	title = {What {Is} a {Good} {Forecast}? {An} {Essay} on the {Nature} of {Goodness} in {Weather} {Forecasting}},
	volume = {8},
	issn = {0882-8156, 1520-0434},
	shorttitle = {What {Is} a {Good} {Forecast}?},
	url = {https://journals.ametsoc.org/view/journals/wefo/8/2/1520-0434_1993_008_0281_wiagfa_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1993)008<0281:WIAGFA>2.0.CO;2},
	abstract = {Abstract Differences of opinion continue to exist among forecasters and users regarding the meaning of "good (bad) weather forecasts" and related expressions of forecast quality and value. After introducing some general considerations, three distinct types of goodness are identified: 1) consistency (or coherence), which is the correspondence between forecasters' judgments and their forecasts; 2) quality (or accuracy), which is the correspondence between forecasts and matching observations; and 3) value (or economic value), which is the incremental economic and/or other benefits realized by decision makers as a result of using the forecasts. Then, specific attributes of consistency, quality, and value of forecastsâ€”in both deterministic and probabilistic formâ€”are examined and illustrative examples are presented. Relationships among these three types of goodness are explored, and implications for the evaluation of forecasts in operational settings are briefly discussed.},
	language = {en},
	number = {2},
	urldate = {2025-06-11},
	journal = {Weather and Forecasting},
	author = {Murphy, Allan H.},
	month = jun,
	year = {1993},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {281--293},
}

@article{bosse_scoring_2023,
	title = {Scoring epidemiological forecasts on transformed scales},
	volume = {19},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011393},
	doi = {10.1371/journal.pcbi.1011393},
	abstract = {Forecast evaluation is a key component of developing reliable epidemic models. Transforming data before running models is a common statistical practice. Forecasting models for epidemiological data often operate on transformed scales such as the log scale, but model comparison and forecast evaluation are usually conducted on the original scale of the data, using incidence counts or deaths. In this work, we demonstrate how this practice of back-transforming forecasts can lead to unintuitive and misleading results. Strictly proper scoring rules, that is scoring rules that are optimised, in expectation, by the true predictive distribution, provide a principled framework for scoring forecasts in the form of predictive distributions and evaluating model performance. We show that if a proper scoring rule is applied to predictions after back-transformation, it may no longer be proper. This can lead to unexpected results in forecast comparisons, with models falsely appearing to have better or worse forecast performance than they do. We argue that to ensure valid model comparisons, forecast evaluation should be conducted on the same scale on which models were trained. We compare different proper scoring rules on transformed and non-transformed scales. Our results show that there is no direct relationship between performance on a transformed scale (e.g., the log scale) and the original scale. To complement scoring on the original scale, we therefore suggest that forecasts are also scored on a transformed scale such as the natural logarithm. Scores on log-transformed values can be interpreted in a multiplicative way as a probabilistic version of a relative error, a common concept in forecast evaluation, and can thus provide additional insight into the quality of predictive performance. In an application to COVID-19 and influenza forecasts, we show empirically that scoring on both the original and a transformed scale provides additional insights into forecast performance.},
	language = {en},
	number = {8},
	urldate = {2025-08-29},
	journal = {PLOS Computational Biology},
	author = {Bosse, Nikos I. and Abbott, Sam and Cori, Anne and van Leeuwen, Edwin and Bracher, Johannes and Funk, Sebastian},
	month = aug,
	year = {2023},
	note = {Publisher: Public Library of Science},
	keywords = {COVID 19, Forecasting, Influenza, SARS CoV 2, Probability distribution, Computer software, Epidemiology, Mathematical models},
	pages = {e1011393},
}
